<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>blog.yui.codes</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2022-10-18T00:28:40+00:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>yui</name>
   <email>yui@yui.codes</email>
 </author>

 
 <entry>
   <title>a lighting/env work in progress</title>
   <link href="http://localhost:4000/2022/09/30/lighting-WIP/"/>
   <updated>2022-09-30T00:00:00+00:00</updated>
   <id>http://localhost:4000/2022/09/30/lighting-WIP</id>
   <content type="html">&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1iyYIFu6s97EwHnvwdr40DRDcie0V5nvR&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I had this vision for a really long time and had collected all sorts of references over the course of several months. Coming from Singapore, I wanted to do something that was like a greenhouse, but in a solarpunk world. Obviously since I am focusing on lighting here, I decided to rework an existing UE5 map to the best of my abilities rather than overscope and start modeling, texturing and everything.&lt;/p&gt;

&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/761259490?h=663757ee36&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;UE5 &amp;amp;quot;Blueprints&amp;amp;quot; - solarpunk relight process video&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I also did another version which was a moody, humid abandoned greenhouse vibe. 
&lt;img src=&quot;https://drive.google.com/uc?id=1ukpEgs6hh3QhQUXxxWk3pvEeLBKEQbaL&quot; /&gt;&lt;/p&gt;

&lt;!--break--&gt;
&lt;p&gt;I tried to do this one with a different, colder fog color, but I actually prefer the first direction I had with this, even if the composition is kind of “neater” or clearer here, with the darkened foreground.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1pIlKFlS19wKs5ZvwWh0eemC9-OSKjq8R&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These were some of my notes from the first pass at this version.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1HX8kIjFEFue8IjhyiYtfF3uND2oIDdOX&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I did a first pass of a third version of this scene, which was a kind of high-class, indoor, night-time building. My first pass was very weird, there was some strange oversaturation in my moonlight and the moonlight was fighting with the warm local lights.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=154AXMfxZhWo3VQP1L6NfMQYnqSlScSD5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I made some progress on it since and now it looks like this with the preview lighting. Maybe one day I will be able to make a process video like I did for the first version of this scene.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=168hlPUHLdOQFrQEtoaWtm8fFLERyQRSs&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I spent a super long time on this and it still isn’t done - I want to try the new lighting on foliage that was released. Lumen Backside Illumination for Two-Sided Foliage was released in the UE5-Main branch, which means that Lumen now scatters indirect light through foliage. Plus, I have a few more ideas for this environment, like a moody, abandoned vibe, or underwater, a night time, etc. So I will take my time with this one and kind of make a little progress on it every now and then.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>lessons in lighting</title>
   <link href="http://localhost:4000/2022/09/15/lighting-lessons/"/>
   <updated>2022-09-15T00:00:00+00:00</updated>
   <id>http://localhost:4000/2022/09/15/lighting-lessons</id>
   <content type="html">&lt;p&gt;Recently, I took a dive into lighting in UE5 over the course of 10?ish weeks under the guidance of Peter Tran. &lt;strong&gt;WARNING:&lt;/strong&gt; Image heavy post…just for this post, I’m adding post truncation to the site.&lt;/p&gt;

&lt;h3 id=&quot;first-attempt&quot;&gt;First Attempt&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1qvnSg3XL8iN8JElBUmzpDDXiiI2yC3Qd&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1wy7Atc_mv9N_eQs-B8uueiu3NyQL6jFl&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For my first delve into studying lighting, I took the old Elemental scene and did two lighting scenes. The goal was primarily to do something that looked different with it and to familiarize myself with the tools available to me in UE5. In particular, I experimented a bit with volumetric lighting and getting some nice light shafts. I also played with the skybox a lot for the first outside image and it was very interesting to try to get a nice sense of depth without losing immersion by manually tweaking blur to emulate depth of field. In this case, I think I would have preferred the mountains to be less clear while not losing too much detail on the clouds, even if that isn’t super physically right I suppose. For the second image, in hindsight, the bottom right corner is a little too dark, but I liked the mood of this scene.&lt;/p&gt;

&lt;h3 id=&quot;second-wind&quot;&gt;Second Wind&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=14QkLt38_AQgKTlXWh3Ii0OhwN8rmT4tz&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This time, I spent a ton of time brainstorming on what kind of project I could do. I browsed through Artstation and decided to pick my favorite artists and do a top-down lighting like in Dota2 or League of Legends.&lt;/p&gt;

&lt;!--break--&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1OpfX8GI3KNhhsuQlK17AAdXQNifrzCNB&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1RkrCR81DeYTPxOSug1BTF8tfYfzq9oX_&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1iSAPgZxLDj5qPr4joaI4_W3Zs53y72Rw&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1pOViDyx7zHofYn8kzR8ZFXn6B-3wFexa&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdna.artstation.com/p/assets/images/images/053/645/260/original/yui-tsmith-breakdown-final.gif?1662679389&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;artblock&quot;&gt;Artblock&lt;/h3&gt;

&lt;p&gt;I struggled a lot to find my next footing. I was changing my point of view and thinking hard about composition, camera angles, and drawing out a scene. But I had difficulty breaking down the ideas of composition between composing with shapes in lighting, and being able to arrange the scene in 3D with geometry. It was kind of like a choice overload, thinking about composition with the pure geometry while simultaneously brainstorming ideas on how to light the scene. I wanted to go for something cinematic, but had a lot of trouble finding the specific direction. 
&lt;img src=&quot;https://drive.google.com/uc?id=1bajzP2kYLrfhGIxsrvsic96Tl4eGtEbx&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1B9K7CgSFreNxu2UFJhQS533WLmnuRRVD&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1uIwoZVhYxQ2kCCPVw_t0OBd5OC-4qyF3&quot; /&gt;
&lt;img src=&quot;https://drive.google.com/uc?id=1A6hieQAFX6M51o_TGs2a-ytUxdDL2mb1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I think it was important to have this struggle. It means that I’m improving and learning to see something differently. But that doesn’t mean it’s not painful! It felt super bad to be in that spot. So I decided to move on and do something that I really wanted to create.&lt;/p&gt;

&lt;p&gt;I had this vision for a really long time and had collected all sorts of references over the course of several months. Coming from Singapore, I wanted to do something that was like a greenhouse, but in a solarpunk world.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1iyYIFu6s97EwHnvwdr40DRDcie0V5nvR&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I spent a super long time on this and it still isn’t done - I want to try the new lighting on foliage that was released. Lumen Backside Illumination for Two-Sided Foliage was released in the UE5-Main branch, which means that Lumen now scatters indirect light through foliage. Plus, I have a few more ideas for this environment, like a moody, abandoned vibe, or underwater, a night time, etc. So I will take my time with this one and kind of make a little progress on it every now and then.&lt;/p&gt;

&lt;p&gt;I will make a separate post about it as I go!&lt;/p&gt;

&lt;h3 id=&quot;moving-forward&quot;&gt;Moving forward&lt;/h3&gt;

&lt;p&gt;Beyond that, I went on do one more lighting exercise which was to light a scene with the character as a focus. I took some inspiration from Liam Wong’s photographs and threw together some assets from the Unreal asset store. 
You can see the final work on my artstation &lt;a href=&quot;https://yuiwei.art/projects/vJqJXD&quot;&gt;here&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cdna.artstation.com/p/assets/images/images/054/314/530/large/yui-highresscreenshot-2022-09-26-12-13-21.jpg?1664264397&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I think I have learnt so much from this. I actually wanted to learn a lot more about the technical side of things, but I think I gained much more than that by growing a lot as an artist and re-learning how to make art, how to make good images, and improve my eye for lighting.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>notes on energy drift in time integrators</title>
   <link href="http://localhost:4000/2019/04/10/time-integration/"/>
   <updated>2019-04-10T00:00:00+00:00</updated>
   <id>http://localhost:4000/2019/04/10/time-integration</id>
   <content type="html">&lt;h2 id=&quot;final-project-idea&quot;&gt;Final Project Idea&lt;/h2&gt;

&lt;p&gt;Energy drift - usually damping - is substantial for numerical integration schemes that are not &lt;a href=&quot;https://en.wikipedia.org/wiki/Symplectic_integrator&quot;&gt;symplectic&lt;/a&gt;, such as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Runge-Kutta&quot;&gt;Runge-Kutta&lt;/a&gt; family.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/Screenshot-2019-03-06-at-12.05.00-PM-1024x619.png&quot; alt=&quot;&quot; class=&quot;wp-image-394&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/Screenshot-2019-03-06-at-12.05.18-PM-1024x628.png&quot; alt=&quot;&quot; class=&quot;wp-image-395&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/Screenshot-2019-03-06-at-12.05.45-PM-1024x542.png&quot; alt=&quot;&quot; class=&quot;wp-image-396&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/Screenshot-2019-03-06-at-12.05.53-PM-1024x597.png&quot; alt=&quot;&quot; class=&quot;wp-image-397&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/Screenshot-2019-03-06-at-12.06.07-PM-1024x634.png&quot; alt=&quot;&quot; class=&quot;wp-image-398&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/Screenshot-2019-03-06-at-12.06.13-PM-1024x642.png&quot; alt=&quot;&quot; class=&quot;wp-image-399&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Symplectic integrators usually used in molecular dynamics, such as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Verlet_integration&quot;&gt;Verlet integrator&lt;/a&gt; family, exhibit increases in energy over very long time scales, though the error remains roughly constant. These integrators do not in fact reproduce the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamiltonian_mechanics&quot;&gt;Hamiltonian mechanics&lt;/a&gt; of the system; instead, they reproduce a closely related “shadow” Hamiltonian whose value they conserve many orders of magnitude more closely.&lt;/p&gt;

&lt;style&gt;.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/VyaJVuRaW9E&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h2 id=&quot;paper-presentation---fepr&quot;&gt;Paper Presentation - FEPR&lt;/h2&gt;

&lt;p&gt;This week we have paper presentations and I talk about this paper to the class, Fast Energy Projection for Real-time Simulation of Deformable Objects by Dinev, Liu et. al. Reference links are at the bottom.&lt;/p&gt;

&lt;div class=&quot;message&quot;&gt;
### Disclaimer
Tiantian Liu made a much better video explaining the paper. You can find that in the references as well. My presentation is very much tailored to the class and what we know collectively, which is not that much.
&lt;/div&gt;
&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/761248367?h=1f6d297779&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;2019 Paper Presentation Recording - FEPR&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;The link to the slides is http://bit.ly/yuifepr&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;References&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.utah.edu/~ladislav/dinev18FEPR/dinev18FEPR.html&quot;&gt;FEPR: Fast Energy Projection for Real-time Simulation of Deformable Objects&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=xyB-VlesB-M&quot;&gt;Superior video by Liu explaining the method they used&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://box2d.org/files/GDC2015/ErinCatto_NumericalMethods.pdf&quot;&gt;Erin Catto’s slides with the mass-spring phase portrait&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://matthias-mueller-fischer.ch/publications/posBasedDyn.pdf&quot;&gt;Position-based Dynamics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.utah.edu/~ladislav/bouaziz14projective/bouaziz14projective.pdf&quot;&gt;Projective Dynamics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.columbia.edu/cg/pdfs/131-ESIC.pdf&quot;&gt;Fast Projection (Goldenthal et al)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stanford.edu/class/ee103/lectures/matrix_examples_slides.pdf&quot;&gt;Selector Matrices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;final-project-presentation&quot;&gt;Final Project Presentation&lt;/h2&gt;

&lt;iframe src=&quot;https://drive.google.com/file/d/1sxFrRZN9afnka3dR_s0ui9CiJLRZiG28/preview&quot; width=&quot;700&quot; height=&quot;800&quot;&gt;&lt;/iframe&gt;
</content>
 </entry>
 
 <entry>
   <title>notes on particle-based systems and deformables</title>
   <link href="http://localhost:4000/2019/03/20/deformables/"/>
   <updated>2019-03-20T00:00:00+00:00</updated>
   <id>http://localhost:4000/2019/03/20/deformables</id>
   <content type="html">&lt;p&gt;Unified particle-based system: 
Smoke done by advecting tiny particles along velocities provided by unified particle system.
Seems like it is a lot of non-physically-based implementations, for example, rigidbody collisions don’t work that way.
But it is convenient to have everything using the same system (maybe).&lt;/p&gt;

&lt;h3 id=&quot;deformables&quot;&gt;Deformables&lt;/h3&gt;
&lt;h4 id=&quot;position-based-dynamics-pbd&quot;&gt;Position-based Dynamics (PBD)&lt;/h4&gt;

&lt;p&gt;At first, Position-based Dynamics seems to be similar to Verlet integrator, which I have previously used for cloth simulation. However, the author highlights that where Verlet stores velocity implicitly with the previous and current position, PBD uses velocities explicitly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i1.wp.com/yuiwei.com/wp-content/uploads/2019/04/pbd1.png?fit=764%2C677&quot; alt=&quot;&quot; class=&quot;wp-image-714&quot; /&gt;&lt;img src=&quot;https://i2.wp.com/yuiwei.com/wp-content/uploads/2019/04/pbd2.png?fit=764%2C642&quot; alt=&quot;&quot; class=&quot;wp-image-715&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Later, I realised that for PBD, we try to treat everything as a constraint, including forces (except general forces like gravity, see my annotation on algorithm. When we used position constraints in the cloth simulation, it seemed to automatically correct for any instabilities given by the numerical integration method. But actually when everything is made into a constraint, this seems to shift the problem from the integration step to the constraint solver. As a result, the stability of PBD no longer depends on time-step but on the shape of the constraint functions.&lt;/p&gt;

&lt;p&gt;TODO: look more into XPBD. Updates soon.&lt;/p&gt;

&lt;h4 id=&quot;finite-element-method&quot;&gt;Finite Element Method&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i2.wp.com/yuiwei.com/wp-content/uploads/2019/04/fracture.png?fit=764%2C556&quot; alt=&quot;&quot; class=&quot;wp-image-712&quot; /&gt;&lt;img src=&quot;https://i2.wp.com/yuiwei.com/wp-content/uploads/2019/04/fracture2.png?fit=764%2C662&quot; alt=&quot;&quot; class=&quot;wp-image-713&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The paper “Breaking Things” video by O’Brien and Hodgins uses continuous model and finite elements made up of tetrahedrons. I was unclear on the meaning of the vector &lt;strong&gt;&lt;em&gt;u&lt;/em&gt;&lt;/strong&gt; in the equations as it does not correspond to vertex locations, instead it refers to the location of the element? Do we just take the center of the tetrahedron as &lt;strong&gt;&lt;em&gt;u&lt;/em&gt;&lt;/strong&gt;? 
Additionally, they say that the rows of &lt;em&gt;β&lt;/em&gt; are the coefficients of the shape functions, which I don’t understand.&lt;/p&gt;

&lt;h4 id=&quot;projective-dynamics&quot;&gt;Projective Dynamics&lt;/h4&gt;

&lt;p&gt;For PBD the constraint solver which does most of the work does it in a “Gauss-Seidel-like fashion”, which means solving each constraint individually independent of each other. When we project particles, the modifications are visible to the process, so the order of constraints is extremely important. For projective dynamics, constraints are taken from a local/global optimization perspective. The authors say that PBD converges to inelastic behaviour (I’m not sure why yet) and PD converges to the “true implicit Euler solution”.&lt;/p&gt;

&lt;p&gt;TODO: Self-study on deformables (lit review)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>week 4-5</title>
   <link href="http://localhost:4000/2019/02/11/class-notes-2/"/>
   <updated>2019-02-11T00:00:00+00:00</updated>
   <id>http://localhost:4000/2019/02/11/class-notes-2</id>
   <content type="html">&lt;h3 id=&quot;motion-editing&quot;&gt;Motion Editing&lt;/h3&gt;

&lt;p&gt;We looked at PRECISION which can figure out what motions go with new geometry. I feel like this tool makes it much easier for large quantities of content in games and animations; however, it didn’t seem like the artists had much control over how animations might look. There were also issues with transitioning between fixed motion captured animations.&lt;/p&gt;

&lt;h3 id=&quot;skinning&quot;&gt;Skinning&lt;/h3&gt;
&lt;p&gt;Linear Blend Skinning is intuitive but the candy-wrapper problem is well known. Dual quaternion skinning I feel is a really smart way of using mathematical properties of quaternions to avoid the candy wrapper effect. But to be honest, skinning of organic bodies to skeletons has a lot of variations that can’t be described just by one algorithm. I guess that’s why there are still so many artists working to do weight-painting all the time.&lt;/p&gt;

&lt;p&gt;On the note of artist input, we looked at &lt;a href=&quot;https://graphics.ethz.ch/publications/papers/paperOzt13.php&quot;&gt;this&lt;/a&gt; paper for using line-of-action concept to generate 3D poses. Although this seemed like a very time-efficient method, the poses generated still needed to be tweaked by artists a fair bit, so I think the added value is not that much.&lt;/p&gt;

&lt;p&gt;On the topic of weight painting, we also looked at &lt;a href=&quot;http://motionlab.kaist.ac.kr/wp-content/uploads/2018/09/SplineSkinning_TOG_CameraReady.pdf&quot;&gt;this&lt;/a&gt; paper on spline-based weight painting. This concept was really exciting to me as an artist who has always found Maya’s weight painting tools to feel very clumsy. Especially because it is hard to tell when your weight painting is blended properly:
&lt;img src=&quot;http://www.3dfiggins.com/writeups/paintingWeights/contents/fig24_knuckle_smoothed.jpg&quot; alt=&quot;&quot; /&gt;
Picture taken from &lt;a href=&quot;http://www.3dfiggins.com/writeups/paintingWeights/&quot;&gt;this really good resource&lt;/a&gt; for learning how difficult and complex the weight-painting process is!&lt;/p&gt;

&lt;p&gt;Using splines to determine the falloff or interpolation of weights seems very elegant. Although I have yet to try using a system like that.&lt;/p&gt;

&lt;p&gt;Using cages to warp the mesh seemed like a really intuitive idea as well. We see cage methods all the time in 2D animation software. I’m pretty sure &lt;a href=&quot;https://www.live2d.com/en/about/whats_live2d&quot;&gt;Live2D &lt;/a&gt;is using a cage deformation method, and it has some really beautiful results. I’m really curious why we don’t see cage methods in 3D more often. It seems really convenient, there are different methods for applying the cage transform to the cuboid or tetrahedron that can be used for artist control. Perhaps it is more difficult to determine what happens at the joints.&lt;/p&gt;

&lt;p&gt;We also looked at implicit functions for mesh wrapping. Seems like we use a bounding mesh as a “cage”, and the bounding mesh can be represented by an implicit function. This method seems like it will not be able to take care of sharp details that well. I also want to read more on implicit functions for meshes as the meta-balls or blobbys idea is unfamiliar to me.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>week 1-3</title>
   <link href="http://localhost:4000/2019/02/04/class-notes/"/>
   <updated>2019-02-04T00:00:00+00:00</updated>
   <id>http://localhost:4000/2019/02/04/class-notes</id>
   <content type="html">&lt;h2 id=&quot;week-1-techniques-for-creating-animation&quot;&gt;Week 1: Techniques for creating animation&lt;/h2&gt;
&lt;p&gt;2D animators make use of keyframes to get poses before doing in-betweens. In 3D, keyframes can be set and automatically tweened. In 2D animation, they often make use of 2s due to not doing all in between frames for 24 fps. In the recent Spiderman animated movie, it was interesting to see that they sometimes used 2s in 3D by stepping the animation curves between keyframes as a stylistic choice.&lt;/p&gt;

&lt;p&gt;Procedural animation has some really cool applications - automatic skinning and animation has been used in games like Spore, where players can make their own creatures. Procedural generation of variants in animation can also help generate some natural look to character’s scripted animation.&lt;/p&gt;

&lt;h2 id=&quot;week-2-3-inverse-kinematics&quot;&gt;Week 2-3: Inverse Kinematics&lt;/h2&gt;

&lt;p&gt;In Week 2, we visited Motion Capture lab in CMU. As I’ve never been in a motion capture lab before, this experience was really enlightening for me. They use infrared cameras and plastic balls wrapped in reflective tape to capture positional data. There were different sized reflective balls for different types of data. For facial capture, the motion capture lab assistant has to reconfigure and calibrate all the infrared cameras. I’ve not used any motion capture system calibration and capture software before, but I think it might be similar to camera calibration systems in computer vision for 3D reconstruction, which I am somewhat more familiar with.&lt;/p&gt;

&lt;h3 id=&quot;inverse-kinematics-methods&quot;&gt;Inverse Kinematics Methods&lt;/h3&gt;

&lt;p&gt;We talked about Jacobian transpose, pseudo-inverse and damped least squares method. We have to implement an inverse kinematics solution for Miniproject 1. Previously I have implemented CCD and I remember it was pretty fast. I seem to have lost my implementation to poor organisation in my filesystem but I did find my pseudo-inverse implementation! Which is much slower!&lt;/p&gt;

&lt;video controls=&quot;&quot; src=&quot;http://yuiwei.com/wp-content/uploads/2019/03/ikfkccd.mp4&quot;&gt;&lt;/video&gt;

&lt;p&gt;Anyway, I can’t remember most of my implementation so I’m looking forward to doing it again. It will be a good chance to revise what I learned. We also looked at more heuristic methods, like CCD. I have heard of FABRIK before, but not from class. Mostly from videos on the internet. But learning about it in class, it seemed really intuitive and to have really nice results. I might try my hand at implementing it somewhere.&lt;/p&gt;
</content>
 </entry>
 

</feed>
